#!/usr/bin/env python3
"""
scripts/auto_orchestrator.py
æ¯æ—¥è‡ªåŠ¨å‘å¸–ç¼–æ’å™¨ â€” ä¸»å…¥å£

æµç¨‹:
  1. åŠ è½½é…ç½® + å†å²
  2. auto_scheduler é€‰æ‹© 3 ä¸ªç›®æ ‡
  3. å¾ªç¯: ç”Ÿæˆå†…å®¹ â†’ ä¿å­˜è‰ç¨¿ â†’ å‘å¸– â†’ è®°å½•æ—¥å¿—
  4. å†™å…¥æ¯æ—¥æŠ¥å‘Š + å‘é€é€šçŸ¥

ç”¨æ³•:
  python3 scripts/auto_orchestrator.py                  # æ­£å¸¸è¿è¡Œ
  python3 scripts/auto_orchestrator.py --dry-run        # åªç”Ÿæˆä¸å‘å¸–
  python3 scripts/auto_orchestrator.py --count 1        # åªå‘ 1 ç¯‡
  python3 scripts/auto_orchestrator.py --no-wait        # ä¸ç­‰å¾…é—´éš”ï¼ˆæµ‹è¯•ç”¨ï¼‰
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime, timezone

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(BASE_DIR, "scripts"))

from auto_scheduler import select_daily_targets, load_json
from auto_content_gen import generate_post, get_api_key
from auto_poster import post_to_reddit
from auto_notify import notify_success, notify_failure, notify_partial

LOCK_FILE = os.path.join(BASE_DIR, "memory", "automation", ".lock")
DAILY_LOG_DIR = os.path.join(BASE_DIR, "memory", "automation")
POSTED_LOG = os.path.join(BASE_DIR, "memory", "posted-log.json")

DEFAULT_CONFIG = {
    "posts_per_day": 3,
    "min_days_between_same_subreddit": 4,
    "min_hours_between_posts": 2.5,
    "content_model": "claude-sonnet-4-20250514",
    "dry_run": False,
    "enable_notifications": True,
    "posting_start_hour_local": 8,
}


def acquire_lock():
    """è·å–é”ï¼ˆé˜²æ­¢å¹¶å‘è¿è¡Œï¼‰"""
    os.makedirs(os.path.dirname(LOCK_FILE), exist_ok=True)
    if os.path.exists(LOCK_FILE):
        try:
            with open(LOCK_FILE) as f:
                pid = int(f.read().strip())
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            os.kill(pid, 0)
            return False  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
        except (ValueError, ProcessLookupError, PermissionError):
            pass  # æ—§é”ï¼Œå¯ä»¥è¦†ç›–

    with open(LOCK_FILE, "w") as f:
        f.write(str(os.getpid()))
    return True


def release_lock():
    """é‡Šæ”¾é”"""
    try:
        os.remove(LOCK_FILE)
    except FileNotFoundError:
        pass


def load_posted_log():
    """åŠ è½½å‘å¸–æ—¥å¿—"""
    if os.path.exists(POSTED_LOG):
        try:
            with open(POSTED_LOG) as f:
                return json.load(f)
        except Exception:
            return []
    return []


def save_posted_log(log):
    """ä¿å­˜å‘å¸–æ—¥å¿—"""
    with open(POSTED_LOG, "w") as f:
        json.dump(log, f, indent=2, ensure_ascii=False)


def count_posts_today(log):
    """è®¡ç®—ä»Šå¤©å·²å‘å¸–æ•°"""
    today = datetime.now().strftime("%Y-%m-%d")
    return sum(1 for p in log if p.get("posted_at", "").startswith(today))


def save_draft(subreddit, angle, title, body):
    """ä¿å­˜è‰ç¨¿åˆ° memory/drafts/"""
    import subprocess
    result = subprocess.run([
        sys.executable, os.path.join(BASE_DIR, "scripts", "save_draft.py"),
        "--subreddit", subreddit,
        "--angle", angle,
        "--title", title,
        "--body", body,
    ], capture_output=True, text=True)
    return result.returncode == 0


def log_post_entry(post_id, url, subreddit, title, angle, draft_file=""):
    """æ·»åŠ åˆ° posted-log.json"""
    log = load_posted_log()
    now = datetime.now(timezone.utc).isoformat()

    entry = {
        "post_id": post_id,
        "url": url,
        "subreddit": subreddit if subreddit.startswith("r/") else f"r/{subreddit}",
        "title": title,
        "angle": angle,
        "draft_file": draft_file,
        "posted_at": now,
        "score": None,
        "upvote_ratio": None,
        "num_comments": None,
        "last_checked": None,
        "status": "active",
        "auto_posted": True,
    }

    log.append(entry)
    save_posted_log(log)
    return entry


def save_daily_log(date_str, results):
    """ä¿å­˜æ¯æ—¥è¿è¡Œæ—¥å¿—"""
    os.makedirs(DAILY_LOG_DIR, exist_ok=True)

    succeeded = sum(1 for r in results if r.get("status") == "success")
    failed = sum(1 for r in results if r.get("status") == "failed")

    daily_log = {
        "date": date_str,
        "started_at": results[0].get("started_at", "") if results else "",
        "completed_at": datetime.now(timezone.utc).isoformat(),
        "posts": results,
        "summary": {
            "attempted": len(results),
            "succeeded": succeeded,
            "failed": failed,
        }
    }

    filepath = os.path.join(DAILY_LOG_DIR, f"daily-log-{date_str}.json")
    with open(filepath, "w") as f:
        json.dump(daily_log, f, indent=2, ensure_ascii=False)

    # ä¹Ÿä¿å­˜ä¸º latest
    latest = os.path.join(DAILY_LOG_DIR, "latest-run.json")
    with open(latest, "w") as f:
        json.dump(daily_log, f, indent=2, ensure_ascii=False)

    return filepath


def run_daily(dry_run=False, count=None, no_wait=False):
    """æ¯æ—¥å‘å¸–ä¸»æµç¨‹"""

    print("\n" + "=" * 60)
    print("ğŸš€ Reddit Assistant â€” è‡ªåŠ¨å‘å¸–")
    print("=" * 60)

    # åŠ è½½é…ç½®
    config = load_json("memory/config.json")
    if not config:
        print("âŒ æœªæ‰¾åˆ°äº§å“é…ç½®")
        return False

    auto_config = load_json("memory/automation-config.json") or DEFAULT_CONFIG.copy()
    for key, val in DEFAULT_CONFIG.items():
        auto_config.setdefault(key, val)

    if dry_run:
        auto_config["dry_run"] = True
        print("ğŸ”¸ DRY RUN æ¨¡å¼ â€” åªç”Ÿæˆä¸å‘å¸–\n")

    # æ£€æŸ¥ API key
    if not get_api_key():
        print("âŒ æœªæ‰¾åˆ° Anthropic API Key")
        print("   export ANTHROPIC_API_KEY=your-key")
        notify_failure("ç¼ºå°‘ Anthropic API Key")
        return False

    # åŠ è½½æ•°æ®
    profiles = load_json("memory/subreddit-profiles.json", [])
    log = load_posted_log()

    if not profiles:
        print("âŒ æ²¡æœ‰ subreddit æ¡£æ¡ˆ")
        return False

    # æ£€æŸ¥ä»Šå¤©å·²å‘å¸–æ•°
    already_posted = count_posts_today(log)
    max_posts = count or auto_config["posts_per_day"]
    remaining = max_posts - already_posted

    if remaining <= 0:
        print(f"âœ… ä»Šå¤©å·²å‘ {already_posted} ç¯‡ï¼Œè¾¾åˆ°ä¸Šé™")
        return True

    print(f"ğŸ“‹ ä»Šå¤©ç›®æ ‡: {remaining} ç¯‡ (å·²å‘ {already_posted} ç¯‡)")

    # é€‰æ‹©ç›®æ ‡
    targets = select_daily_targets(profiles, log, config=auto_config)
    if not targets:
        print("âŒ æ‰€æœ‰ subreddit éƒ½åœ¨å†·å´æœŸå†…")
        return False

    targets = targets[:remaining]
    print(f"ğŸ¯ é€‰å®šç›®æ ‡: {', '.join(t['subreddit'] for t in targets)}\n")

    # æ‰§è¡Œå‘å¸–
    results = []
    succeeded_subs = []
    wait_hours = auto_config["min_hours_between_posts"]
    model = auto_config.get("content_model")

    for i, target in enumerate(targets):
        sub = target["subreddit"]
        angle = target["angle"]
        angle_names = {"A": "Story/Journey", "B": "Feedback Request", "C": "Value/Insight"}

        print(f"\n{'â”€' * 50}")
        print(f"[{i+1}/{len(targets)}] {sub} â€” è§’åº¦ {angle} ({angle_names.get(angle, '?')})")
        print(f"{'â”€' * 50}")

        result = {
            "slot": i + 1,
            "subreddit": sub,
            "angle": angle,
            "started_at": datetime.now(timezone.utc).isoformat(),
        }

        # Step 1: ç”Ÿæˆå†…å®¹
        print("\n  ğŸ“ æ­£åœ¨ç”Ÿæˆå†…å®¹...")
        try:
            # é‡æ–°åŠ è½½ log ä»¥åŒ…å«æœ¬æ¬¡è¿è¡Œä¸­å·²å‘çš„å¸–å­
            current_log = load_posted_log()
            post_content = generate_post(
                target["profile"], config, current_log, angle, model=model
            )
        except Exception as e:
            print(f"  âŒ å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            result.update({"status": "failed", "error": str(e)})
            results.append(result)
            continue

        if not post_content:
            print("  âŒ å†…å®¹ç”Ÿæˆè¿”å›ç©º")
            result.update({"status": "failed", "error": "ç”Ÿæˆè¿”å›ç©º"})
            results.append(result)
            continue

        title = post_content["title"]
        body = post_content["body"]
        print(f"  âœ… å†…å®¹ç”ŸæˆæˆåŠŸ")
        print(f"  ğŸ“Œ æ ‡é¢˜: {title}")

        # Step 2: ä¿å­˜è‰ç¨¿
        save_draft(sub, angle, title, body)

        # Step 3: å‘å¸–
        print("\n  ğŸš€ æ­£åœ¨å‘å¸–...")
        try:
            post_result = post_to_reddit(
                sub, title, body,
                dry_run=auto_config.get("dry_run", False),
                verify=not auto_config.get("dry_run", False)
            )
        except Exception as e:
            print(f"  âŒ å‘å¸–å¤±è´¥: {e}")
            result.update({"status": "failed", "error": str(e), "title": title})
            results.append(result)
            continue

        if post_result["success"]:
            print(f"  âœ… å‘å¸–æˆåŠŸ: {post_result.get('url', 'DRY_RUN')}")

            # Step 4: è®°å½•æ—¥å¿—
            if not post_result.get("dry_run"):
                log_post_entry(
                    post_id=post_result["post_id"],
                    url=post_result["url"],
                    subreddit=sub,
                    title=title,
                    angle=angle,
                )

            result.update({
                "status": "success",
                "title": title,
                "post_id": post_result.get("post_id", ""),
                "url": post_result.get("url", ""),
                "verified": post_result.get("verified", True),
                "attempts": post_content.get("attempts", 1),
            })
            succeeded_subs.append(sub)
        else:
            print(f"  âŒ å‘å¸–å¤±è´¥: {post_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            result.update({
                "status": "failed",
                "title": title,
                "error": post_result.get("error", ""),
            })

        results.append(result)

        # ç­‰å¾…é—´éš”
        if i < len(targets) - 1 and not no_wait:
            wait_seconds = int(wait_hours * 3600)
            print(f"\n  â³ ç­‰å¾… {wait_hours} å°æ—¶åå‘ä¸‹ä¸€ç¯‡...")
            time.sleep(wait_seconds)

    # æ€»ç»“
    print(f"\n{'=' * 60}")
    succeeded = sum(1 for r in results if r["status"] == "success")
    failed = sum(1 for r in results if r["status"] == "failed")
    print(f"ğŸ“Š å®Œæˆ: {succeeded} æˆåŠŸ / {failed} å¤±è´¥")

    for r in results:
        icon = "âœ…" if r["status"] == "success" else "âŒ"
        print(f"  {icon} {r['subreddit']} â€” {r.get('title', '?')[:50]}")
        if r["status"] == "success" and r.get("url"):
            print(f"     {r['url']}")

    # ä¿å­˜æ¯æ—¥æ—¥å¿—
    today_str = datetime.now().strftime("%Y-%m-%d")
    log_path = save_daily_log(today_str, results)
    print(f"\nğŸ“ æ—¥å¿—: {log_path}")

    # å‘é€é€šçŸ¥
    if auto_config.get("enable_notifications", True):
        if failed == 0 and succeeded > 0:
            notify_success(succeeded, succeeded_subs)
        elif succeeded > 0:
            notify_partial(succeeded, failed, succeeded_subs)
        elif failed > 0:
            notify_failure(f"{failed} ç¯‡å…¨éƒ¨å¤±è´¥")

    print("=" * 60 + "\n")
    return failed == 0


def main():
    os.chdir(BASE_DIR)

    parser = argparse.ArgumentParser(description="Reddit æ¯æ—¥è‡ªåŠ¨å‘å¸–ç¼–æ’å™¨")
    parser.add_argument("--dry-run", action="store_true", dest="dry_run",
                        help="åªç”Ÿæˆå†…å®¹ä¸å®é™…å‘å¸–")
    parser.add_argument("--count", type=int, default=None,
                        help="å‘å¸–æ•°é‡ (é»˜è®¤: é…ç½®æ–‡ä»¶ä¸­çš„ posts_per_day)")
    parser.add_argument("--no-wait", action="store_true", dest="no_wait",
                        help="ä¸ç­‰å¾…å¸–å­é—´éš” (æµ‹è¯•ç”¨)")
    args = parser.parse_args()

    # è·å–é”
    if not acquire_lock():
        print("âš ï¸  å¦ä¸€ä¸ªå®ä¾‹æ­£åœ¨è¿è¡Œï¼Œé€€å‡º")
        sys.exit(0)

    try:
        success = run_daily(
            dry_run=args.dry_run,
            count=args.count,
            no_wait=args.no_wait,
        )
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æœªå¤„ç†çš„å¼‚å¸¸: {e}")
        notify_failure(str(e)[:100])
        sys.exit(1)
    finally:
        release_lock()


if __name__ == "__main__":
    main()
